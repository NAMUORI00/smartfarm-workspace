services:
  # ==============================================================================
  # Research / Benchmarking add-on compose
  #
  # Use together with the service stack:
  #   docker compose -f docker-compose.yml -f docker-compose.research.yml up -d
  #
  # Optional one-shot utilities (recommended):
  #   docker compose -f docker-compose.yml -f docker-compose.research.yml --profile research run --rm indexer-v2
  #   docker compose -f docker-compose.yml -f docker-compose.research.yml --profile benchmark run --rm benchmark
  #
  # Note:
  #   - Services here are behind profiles to avoid extra containers by default.
  #   - Indexing is LLM-free (Tri-Graph v2), so we no longer run a separate llama-index container.
  # ==============================================================================

  # ==============================================================================
  # Tri-Graph v2 index build (offline, LLM-free)
  #
  # Builds Dense(FAISS) + Sparse(BM25) + Tri-Graph artifacts from a corpus JSONL.
  # Runs once (idempotent; skips if artifacts already exist).
  # ==============================================================================
  indexer-v2:
    build:
      context: ./smartfarm-search
      dockerfile: Dockerfile
    image: smartfarm-rag-api:latest
    profiles: ["research", "benchmark", "e2e"]
    container_name: smartfarm-indexer-v2
    environment:
      - EMBED_MODEL_ID=${EMBED_MODEL_ID:-minilm}
      - TRIGRAPH_REBUILD=${TRIGRAPH_REBUILD:-0}
      - TRIGRAPH_INDEX_LIMIT=${TRIGRAPH_INDEX_LIMIT:-400}
      - TRIGRAPH_LANG=${TRIGRAPH_LANG:-ko}
      - TRIGRAPH_INPUT_JSONL=${TRIGRAPH_INPUT_JSONL:-/workspace/smartfarm-search/data/agriqa/corpus.jsonl}
      # Keep outputs configurable so E2E runs can be data-isolated (see docker-compose.e2e.yml)
      - INDEX_DIR=${INDEX_DIR:-data/index}
      - TRIGRAPH_INDEX_DIR=${TRIGRAPH_INDEX_DIR:-data/index/trigraph_edge}
    volumes:
      - ./smartfarm-search:/workspace/smartfarm-search
      - ./smartfarm-ingest:/workspace/smartfarm-ingest
      - ./smartfarm-search/.cache:/root/.cache
    working_dir: /workspace
    networks: ["private_net"]
    healthcheck:
      disable: true
    entrypoint: ["sh", "-lc"]
    command:
      - |
        set -eu
        # Resolve output dirs (absolute or repo-relative)
        if [ "$${INDEX_DIR#/*}" != "$${INDEX_DIR}" ]; then
          INDEX_ABS="$${INDEX_DIR}"
        else
          INDEX_ABS="/workspace/smartfarm-search/$${INDEX_DIR}"
        fi
        if [ "$${TRIGRAPH_INDEX_DIR#/*}" != "$${TRIGRAPH_INDEX_DIR}" ]; then
          TRI_ABS="$${TRIGRAPH_INDEX_DIR}"
        else
          TRI_ABS="/workspace/smartfarm-search/$${TRIGRAPH_INDEX_DIR}"
        fi

        META="$${TRI_ABS}/meta.json"
        if [ "$${TRIGRAPH_REBUILD}" != "1" ] && [ -f "$${META}" ]; then
          echo "[index] Tri-Graph artifacts already exist: $${META} (skip; set TRIGRAPH_REBUILD=1 to rebuild)"
          exit 0
        fi

        INPUT="$${TRIGRAPH_INPUT_JSONL}"
        if [ ! -f "$${INPUT}" ]; then
          echo "[index][WARN] input not found: $${INPUT} -> falling back to agriqa corpus"
          INPUT="/workspace/smartfarm-search/data/agriqa/corpus.jsonl"
        fi

        python /workspace/smartfarm-ingest/scripts/indexing/build_trigraph_index_v2.py \
          --input-jsonl "$${INPUT}" \
          --lang "$${TRIGRAPH_LANG}" \
          --embed-model-id "$${EMBED_MODEL_ID}" \
          --limit "$${TRIGRAPH_INDEX_LIMIT}" \
          --index-dir "$${INDEX_ABS}" \
          --trigraph-dir "$${TRI_ABS}"
    restart: "no"

  # ==============================================================================
  # Agriculture RAGAS benchmark runner (smartfarm-benchmarking) - runs once
  #
  # Example:
  #   docker compose -f docker-compose.yml -f docker-compose.research.yml run --rm benchmark
  # ==============================================================================
  benchmark:
    build:
      context: ./smartfarm-benchmarking
      dockerfile: benchmarking/docker/Dockerfile
    image: era-benchmark:latest
    profiles: ["benchmark", "ragas"]
    container_name: smartfarm-benchmark
    # NOTE:
    #   - Uses AgXQA (public agriculture QA) and RAGAS metrics.
    #   - Legacy wasabi/wassabi dataset inputs are blocked by runtime guard.
    entrypoint: ["python", "-m", "benchmarking.experiments.ragas_agriculture_benchmark"]
    command:
      - --out
      - /app/output/graph_effectiveness/main_v4.json
      - --protocol-id
      - ${GRAPH_PROTOCOL_ID:-graphrag_effectiveness_v4}
      - --frozen-config
      - /app/benchmarking/configs/graphrag_effectiveness_v4.yaml
      - --k
      - ${RAGAS_TOP_K:-4}
      - --max-queries
      - ${RAGAS_MAX_QUERIES:-200}
      - --seed
      - ${RAGAS_SEED:-42}
      - --ragas-model
      - ${RAGAS_MODEL:-openai/gpt-oss-120b}
      - --ragas-base-url
      - ${OPENAI_BASE_URL}
      - --ragas-api-key
      - ${API_KEY}
    environment:
      - PYTHONUNBUFFERED=1
      - SMARTFARM_WORKSPACE_ROOT=/workspace
      - SMARTFARM_SEARCH_ROOT=/workspace/smartfarm-search
      - LLMLITE_HOST=${LLMLITE_HOST:-http://llama:8080}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL}
      - API_KEY=${API_KEY}
      - OPENAI_API_KEY=${API_KEY}
      - RAGAS_ANSWER_RELEVANCY_STRICTNESS=${RAGAS_ANSWER_RELEVANCY_STRICTNESS:-1}
      - RAGAS_METRIC_MAX_RETRIES=${RAGAS_METRIC_MAX_RETRIES:-2}
      - RAGAS_LLM_TIMEOUT_SEC=${RAGAS_LLM_TIMEOUT_SEC:-60}
      - RAGAS_LLM_MAX_RETRIES=${RAGAS_LLM_MAX_RETRIES:-1}
      - RAGAS_JUDGE_MAX_TOKENS=${RAGAS_JUDGE_MAX_TOKENS:-512}
      - RAGAS_RUN_MAX_WORKERS=${RAGAS_RUN_MAX_WORKERS:-2}
      - RAGAS_EVAL_HARD_TIMEOUT_SEC=${RAGAS_EVAL_HARD_TIMEOUT_SEC:-900}
      # Benchmark reproducibility: keep answer generation deterministic by default.
      - TEMPERATURE=${PAPER_EVAL_TEMPERATURE:-0.0}
      - LLMLITE_SEED=${PAPER_EVAL_LLM_SEED:-42}
    volumes:
      - ./output:/app/output
      # Use workspace source directly to avoid stale image code during protocol debugging.
      - ./smartfarm-benchmarking/benchmarking:/app/benchmarking:ro
      - ./smartfarm-search:/workspace/smartfarm-search:ro
      - ./smartfarm-benchmarking/.cache:/root/.cache
      - ./smartfarm-search/.cache/huggingface/hub/models--Qwen--Qwen3-Embedding-0.6B:/root/.cache/huggingface/hub/models--Qwen--Qwen3-Embedding-0.6B:ro
      - ./smartfarm-search/.cache/huggingface/hub/models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2:/root/.cache/huggingface/hub/models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2:ro
    working_dir: /app
    depends_on:
      llama:
        condition: service_healthy
    networks:
      - private_net
      - ingress_net
    restart: "no"

  # ==============================================================================
  # Full E2E runner (runs once)
  #
  # Example:
  #   E2E_RUN_ID=$(date -u +%Y%m%dT%H%M%SZ) \
  #   docker compose -f docker-compose.yml -f docker-compose.research.yml -f docker-compose.e2e.yml --profile e2e run --rm e2e
  # ==============================================================================
  e2e:
    build:
      context: ./smartfarm-search
      dockerfile: Dockerfile
    image: smartfarm-rag-api:latest
    profiles: ["e2e"]
    container_name: smartfarm-e2e
    healthcheck:
      disable: true
    depends_on:
      api:
        condition: service_healthy
      llama:
        condition: service_healthy
      ingest-worker:
        condition: service_started
      indexer-v2:
        condition: service_completed_successfully
    networks: ["private_net"]
    volumes:
      - ./scripts:/scripts:ro
      - ./output:/app/output
      - ./smartfarm-search/data:/app/data
    entrypoint: ["python", "/scripts/e2e_stack.py"]
    command: ["--timeout", "300"]
    restart: "no"
