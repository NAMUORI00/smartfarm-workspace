# 참고문헌 (References)

[1] Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." *NeurIPS 2020*. ([링크](https://arxiv.org/abs/2005.11401))

[2] Gao, Y., et al. (2024). "Retrieval-Augmented Generation for Large Language Models: A Survey." *arXiv:2312.10997*. ([링크](https://arxiv.org/abs/2312.10997))

[3] Edge, D., et al. (2024). "From Local to Global: A Graph RAG Approach to Query-Focused Summarization." *arXiv:2404.16130*. ([링크](https://arxiv.org/abs/2404.16130))

[4] Guo, Z., et al. (2024). "LightRAG: Simple and Fast Retrieval-Augmented Generation." *arXiv:2410.05779*. ([링크](https://arxiv.org/abs/2410.05779))

[5] Chen, B., et al. (2025). "PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths." *arXiv:2502.14902*. ([링크](https://arxiv.org/abs/2502.14902))

[6] Zhuang, L., Chen, S., Xiao, Y., Zhou, H., Zhang, Y., Chen, H., Zhang, Q., & Huang, X. (2025). "LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora." *arXiv:2510.10114*. ([링크](https://arxiv.org/abs/2510.10114))

[7] Wu, H., Xie, N., Wang, X., Fan, J., Li, Y., & Zhibo, M. (2025). "Crop GraphRAG: Pest and Disease Knowledge Base Q&A System for Sustainable Crop Protection." *Frontiers in Plant Science*. ([링크](https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2025.1696872))

[8] Yang, J., Yang, W., Yang, S., He, L., & Zhang, D. (2025). "Intelligent Q&A Method for Crop Pests and Diseases Using LLM Augmented by Adaptive Hybrid Retrieval." *Smart Agriculture*. ([링크](https://www.smartag.net.cn/EN/10.12133/j.smartag.SA202506026))

[9] Ray, P. P., & Pradhan, M. P. (2025). "AgroMetLLM: An Evapotranspiration and Agro-advisory System Using Localized Large Language Models in Resource-constrained Edge." *Journal of Agrometeorology*, 27(3), 320-326. ([링크](https://doi.org/10.54386/jam.v27i3.3081))

[10] Karpukhin, V., et al. (2020). "Dense Passage Retrieval for Open-Domain Question Answering." *EMNLP 2020*. ([링크](https://arxiv.org/abs/2004.04906))

[11] Yang, Y., et al. (2024). "Cluster-based Partial Dense Retrieval Fused with Sparse Text Retrieval." *SIGIR 2024*. ([링크](https://dl.acm.org/doi/10.1145/3626772.3657972))

[12] Cormack, G. V., Clarke, C. L. A., & Büttcher, S. (2009). "Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods." *SIGIR 2009*. ([링크](https://dl.acm.org/doi/10.1145/1571941.1572114))

[13] Bhuyan, M., et al. (2021). "An Ontological Knowledge Representation for Smart Agriculture." *IEEE BigData 2021*. ([링크](https://arxiv.org/abs/2112.12768))

[14] Ahmadzai, H., et al. (2024). "Innovative Agricultural Ontology Construction Using NLP." *Engineering Science and Technology, an International Journal*, 53, 101699. ([링크](https://www.sciencedirect.com/science/article/pii/S2215098624000612))

[15] Cornei, L., Cornei, D., & Foșalău, C. (2024). "An Ontology-Driven Solution for Capturing Spatial and Temporal Dynamics in Smart Agriculture." *RCIS 2024, LNBIP vol 513*. ([링크](https://link.springer.com/book/10.1007/978-3-031-59465-6))

[16] Yan, R., et al. (2025). "A Knowledge Graph for Crop Diseases and Pests in China (CropDP-KG)." *Scientific Data*. ([링크](https://www.nature.com/articles/s41597-025-04492-0))

[17] Yang, J., et al. (2022). "A Survey on Extraction of Causal Relations from Natural Language Text." *Knowledge and Information Systems*. ([링크](https://arxiv.org/abs/2101.06426))

[18] Liu, C., et al. (2024). "CaEXR: A Joint Extraction Framework for Causal Relationships Based on Word-Pair Network." *ICIC 2024, LNCS vol 14878*. ([링크](https://link.springer.com/chapter/10.1007/978-981-97-5672-8_38))

[19] Xu, Z., et al. (2025). "Sustainable LLM Inference for Edge AI: Evaluating Quantized LLMs." *arXiv:2504.03360*. ([링크](https://arxiv.org/abs/2504.03360))

[20] Gerganov, G. (2024). "llama.cpp: LLM Inference in C/C++." *GitHub*. ([링크](https://github.com/ggml-org/llama.cpp))

[21] Seemakhupt, K., et al. (2024). "EdgeRAG: Online-Indexed RAG for Edge Devices." *arXiv:2412.21023*. ([링크](https://arxiv.org/abs/2412.21023))

[22] Es, S., James, J., Espinosa-Anke, L., & Schockaert, S. (2024). "RAGAS: Automated Evaluation of Retrieval Augmented Generation." *EACL 2024 System Demonstrations*. ([링크](https://arxiv.org/abs/2309.15217))

[23] Saad-Falcon, J., Khattab, O., Potts, C., & Zaharia, M. (2024). "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems." *NAACL 2024*, 338-354. ([링크](https://arxiv.org/abs/2311.09476))

[24] Niu, Y., et al. (2024). "RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented Generation." *arXiv:2408.08067*. ([링크](https://arxiv.org/abs/2408.08067))

[25] Yang, X., Sun, K., Xin, H., Sun, Y., Bhalla, N., Chen, X., et al. (2024). "CRAG -- Comprehensive RAG Benchmark." *arXiv:2406.04744*. ([링크](https://arxiv.org/abs/2406.04744))

[26] Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). "The PageRank Citation Ranking: Bringing Order to the Web." *Technical Report*. ([링크](http://ilpubs.stanford.edu:8090/422/))

[27] Robertson, S., & Zaragoza, H. (2009). "The Probabilistic Relevance Framework: BM25 and Beyond." *Foundations and Trends in Information Retrieval*, 3(4), 333–389. ([링크](https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf))

[28] Johnson, J., Douze, M., & Jégou, H. (2017). "Billion-scale similarity search with GPUs." *arXiv:1702.08734*. ([링크](https://arxiv.org/abs/1702.08734))

[29] Thakur, N., Reimers, N., Rücklé, A., Srivastava, A., & Gurevych, I. (2021). "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models." *NeurIPS 2021 Datasets and Benchmarks*. ([링크](https://arxiv.org/abs/2104.08663))

[30] Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., & Liang, P. (2023). "Lost in the Middle: How Language Models Use Long Contexts." *Transactions of the Association for Computational Linguistics*. ([링크](https://arxiv.org/abs/2307.03172))

[31] OpenAI. (2022-). "tiktoken: a fast BPE tokeniser for use with OpenAI's models." *GitHub*. ([링크](https://github.com/openai/tiktoken))

[32] MSU-CECO. (2024). "AgXQA v1: Agriculture-domain QA benchmark dataset." *Hugging Face Datasets*. ([링크](https://huggingface.co/datasets/msu-ceco/agxqa_v1))

[33] Ho, X., Nguyen, A.-K. D., Sugawara, S., & Aizawa, A. (2020). "Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps." *COLING 2020*. ([링크](https://arxiv.org/abs/2011.01060))

[34] Khattab, M., et al. (2025). "Comparative Evaluation of Arabic RAG Pipelines with RAGAS." *arXiv:2506.06339*. ([링크](https://arxiv.org/abs/2506.06339))

[35] Patel, R., et al. (2025). "Legal Domain RAG Evaluation with RAGAS, BERTScore and ROUGE." *arXiv:2508.13107*. ([링크](https://arxiv.org/abs/2508.13107))

[36] Zhang, Y., et al. (2025). "Energy Graph-RAG Evaluation using RAGAS Properties." *arXiv:2511.01643*. ([링크](https://arxiv.org/abs/2511.01643))

[37] Jain, S., et al. (2024). "On the Reliability of LLM-as-a-Judge." *arXiv:2412.12509*. ([링크](https://arxiv.org/abs/2412.12509))

[38] Guo, Z., et al. (2025). "RAG-Anything: Building Multimodal AI with Any Data." *arXiv:2510.12323*. ([링크](https://arxiv.org/abs/2510.12323))

[39] FalkorDB. (2024). "FalkorDB: A Super Fast Graph Database Using GraphBLAS." *GitHub*. ([링크](https://github.com/FalkorDB/FalkorDB))

[40] Qdrant. (2024). "Qdrant: High-Performance Vector Search Engine." *GitHub*. ([링크](https://github.com/qdrant/qdrant))

[41] OpenDataLab. (2024). "MinerU: An Open-Source Solution for Precise Document Content Extraction." *GitHub*. ([링크](https://github.com/opendatalab/MinerU))

[42] Alibaba. (2025). "Qwen3 Technical Report." *Qwen Blog*. ([링크](https://qwenlm.github.io/blog/qwen3/))

[43] FedE4RAG. (2024). "Federated Learning for Privacy-Preserving RAG Systems." *GitHub*. ([링크](https://github.com/FedE4RAG))

[44] DP-FedLoRA. (2025). "Differentially Private Federated LoRA for On-Device LLM Fine-Tuning." *arXiv preprint*.

[45] Graphiti. (2025). "Building Real-Time Knowledge Graphs with Incremental Updates." *GitHub*. ([링크](https://github.com/getzep/graphiti))

[46] MoonshotAI. (2025). "Kimi-K2.5: Scaling Reinforcement Learning with LLMs." *Hugging Face*. ([링크](https://huggingface.co/moonshotai/Kimi-K2.5))

[47] Xu, M., et al. (2024). "Limitations of Cross-Encoders on Structured Data: Graph Flattening in Edge Retrievers." *arXiv preprint*.

[48] Lin, J., Nogueira, R., & Yates, A. (2021). "Pretrained Transformers for Text Ranking: BERT and Beyond." *Synthesis Lectures on Human Language Technologies*, 14(4), 1-325. ([링크](https://arxiv.org/abs/2010.06467))

[49] Cormack, G. V., Clarke, C. L. A., & Buettcher, S. (2009). "Reciprocal rank fusion outperforms borda count and condorcet in document routing." *SIGIR*. ([링크](https://dl.acm.org/doi/10.1145/1571941.1572114))
