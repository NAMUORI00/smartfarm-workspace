% Section 3: Methodology
% Converted from: 03_methodology.md
% Updated: 2026-01-16 - Applied 3-Column horizontal layout with dataset-pipeline integration

\section{제안 방법론 (Proposed Methodology)}
\label{sec:methodology}

\subsection{전체 시스템 개요 및 처리 흐름}

본 연구는 스마트팜 현장의 자원 제약 환경(8GB RAM)에서 근거 기반 실시간 응답을 제공하는 온디바이스 RAG 시스템을 제안한다. Figure~\ref{fig:full_flow}는 연구 전체 생애주기와 시스템 아키텍처를 \textbf{3-Column 가로 배치}로 제시한다:

\begin{itemize}
	\item \textbf{Phase 1 (좌측, 청색)}: 데이터 수집 및 인덱스 구축 (Offline, One-time)
	\item \textbf{Phase 2 (중앙, 청색)}: 런타임 추론 파이프라인 (Online, Per-query)
	\item \textbf{Evaluation Protocol (우측, 주황색)}: Dataset 생성 + 검증/평가 방법론
\end{itemize}

\subsubsection{End-to-End 처리 흐름}

% [Figure 1 - 3-Column Horizontal Layout - ASCII Art based design]
% For production: Replace with TikZ or external PDF/EPS figure
\begin{figure*}[htbp]
	\centering
	\begin{footnotesize}
		\begin{verbatim}
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃                              ERA-SmartFarm-RAG: End-to-End Research Pipeline                          ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃  PHASE 1: Data & Index Build ┃  PHASE 2: Runtime Inference   ┃  EVALUATION PROTOCOL                    ┃
┃  (Offline, One-time)         ┃  (Online, Per-query)          ┃  (Research Methodology)                 ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃ ① Data Collection            ┃ ④ Query Analysis              ┃ Dataset Generation (dataset-pipeline)  ┃
┃   • Web Crawl (Wiki, Brit.)  ┃   • OntologyMatcher.match()   ┃   Self-Instruct → Evol-Instruct → RAFT ┃
┃   • PDF, EN/KO Bilingual     ┃   • Dynamic Alpha Tuning      ┃   → LLM-as-a-Judge + Prometheus        ┃
┃         ↓                    ┃         ↓                     ┃         ↓                              ┃
┃ ② Preprocessing              ┃ ⑤ HybridDAT Retrieval         ┃ QA Dataset: 220 pairs, ROUGE-L 0.93    ┃
┃   • OCR (EasyOCR)            ┃   Dense | Sparse | PathRAG    ┃                                        ┃
┃   • Chunking, Metadata       ┃   Score Fusion                ┃ Verification:                          ┃
┃   • EN→KO Translation        ┃         ↓                     ┃   Source Attribution, Groundedness     ┃
┃         ↓                    ┃ ⑥ Context Shaping             ┃                                        ┃
┃ ③ Knowledge Store            ┃   Crop Filter, Semantic Dedup ┃ Ablation Study:                        ┃
┃   • dense.faiss (mmap)       ┃         ↓                     ┃   Dense-only, Sparse-only, w/o PathRAG ┃
┃   • sparse.pkl (TF-IDF)      ┃ ⑥.5 Reranking (RAM-aware)     ┃                                        ┃
┃   • Causal Graph             ┃   BGE / LLM-lite / none       ┃ Metrics:                               ┃
┃   • ontology.json (6 types)  ┃         ↓                     ┃   Retrieval: Recall@k, Precision, MRR  ┃
┃                              ┃ ⑦ LLM Generation              ┃   Edge: Latency (p50/p95), Memory      ┃
┃   ~100 docs, ~400 chunks     ┃   Qwen3-0.6B Q4_K_M           ┃   Answer: LLM-as-a-Judge Score         ┃
┃                              ┃   Fallback Chain              ┃                                        ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
LEGEND: System Pipeline (Phase 1-2) deployed on edge device (8GB RAM, Jetson Orin Nano)
        Evaluation Protocol: Research methodology (offline analysis)
	\end{verbatim}
	\end{footnotesize}
	\caption{ERA-SmartFarm-RAG 시스템의 3-Column 가로 배치 아키텍처. Phase 1(데이터 수집 및 인덱싱), Phase 2(런타임 추론), Evaluation Protocol(데이터셋 생성 및 평가)을 한눈에 비교 가능하도록 구성.}
	\label{fig:full_flow}
\end{figure*}

\textbf{System Pipeline (7단계)}:

\begin{table}[htbp]
	\centering
	\small
	\begin{tabular}{c|l|p{8.5cm}}
		\hline
		\textbf{단계} & \textbf{구성요소}   & \textbf{설명}                                                                                     \\
		\hline
		①           & Data Collection & Web Crawl (Wikipedia, Britannica), 농촌진흥청 PDF, 스마트팜코리아 가이드, EN/KO Bilingual                      \\
		②           & Preprocessing   & OCR (EasyOCR), Sentence-window chunking, Metadata tagging, EN→KO Translation (gemini-2.5-flash) \\
		③           & Knowledge Store & dense.faiss (mmap), sparse.pkl (TF-IDF), Causal Graph (in-memory), ontology.json (6 types)      \\
		④           & Query Analysis  & 온톨로지 매칭, Dynamic Alpha (수치→α\_s+0.2, 환경/영양→α\_s+0.1, 병해/재배→α\_p~0.3-0.4)                        \\
		⑤           & HybridDAT       & 3채널 하이브리드 검색 (Dense FAISS + Sparse TF-IDF + PathRAG BFS 2-hop) + Score Fusion                   \\
		⑥           & Context Shaping & Crop Filter (+0.5/×0.15), Semantic Dedup (θ=0.85), Memory-aware Reranking                       \\
		⑦           & LLM Generation  & Qwen3-0.6B Q4\_K\_M, Fallback Chain (Exact→Similar→Template→Search-only)                        \\
		\hline
	\end{tabular}
\end{table}

\textbf{Evaluation Protocol (dataset-pipeline 기반)}:

\begin{table}[htbp]
	\centering
	\small
	\begin{tabular}{l|l|p{6.5cm}}
		\hline
		\textbf{구성요소}      & \textbf{방법론}                      & \textbf{설명}                                      \\
		\hline
		Dataset Generation & Self-Instruct (Wang, ACL23)       & Seed questions에서 다양한 질문 자동 생성                    \\
		                   & Evol-Instruct (Xu, ICLR23)        & 복잡도 점진적 진화 (basic→intermediate→advanced)         \\
		                   & RAFT (Zhang, COLM24)              & Context-grounded answer generation               \\
		                   & LLM-as-a-Judge (Zheng, NeurIPS24) & 다차원 품질 평가 (Groundedness, Accuracy, Completeness) \\
		\hline
		QA Dataset         & 220 pairs                         & 6 categories, ROUGE-L diversity 0.93             \\
		\hline
		Metrics            & Retrieval Quality                 & Recall@k, Precision@k, MRR                       \\
		                   & Edge Performance                  & Latency (p50/p95/p99), Memory, Throughput        \\
		                   & Answer Quality                    & LLM-as-a-Judge Score (1-5), Hallucination Rate   \\
		\hline
	\end{tabular}
\end{table}

\textbf{핵심 설계 원칙}:
\begin{enumerate}
	\item \textbf{오프라인 사전 구축}: 인덱싱/인과관계 그래프(in-memory 빌드)는 1회 오프라인으로 수행하여 런타임 부하 최소화
	\item \textbf{메모리 효율}: mmap 기반 lazy loading으로 전체 인덱스를 RAM에 올리지 않음
	\item \textbf{도메인 특화}: 온톨로지 + Dynamic Alpha 휴리스틱으로 범용 RAG 대비 검색 품질 향상
	\item \textbf{데이터셋 생성}: 검증된 연구 방법론 (Self-Instruct, Evol-Instruct, RAFT, LLM-as-a-Judge) 적용
	\item \textbf{검증 분리}: Groundedness Checks + Prompt Constraints는 Evaluation Protocol로 분리하여 학술적 규약 준수
\end{enumerate}

\textit{Note: Evaluation Protocol (Dataset Generation, Verification, Ablation, Benchmark)은 시스템 구성요소가 아닌 연구 방법론으로, Section~\ref{sec:experiments}에서 상세히 다룬다. Dataset은 dataset-pipeline 프로젝트로 생성되었으며, Benchmark는 내부 베이스라인(Dense-only, Sparse-only, Naive Hybrid)과 비교한다.}

\subsubsection{리소스 제약 및 설계 목표}

엣지 환경의 리소스 제약을 명확히 정의하고, 이를 기반으로 각 컴포넌트를 설계하였다.

\input{tables/methodology/resource-constraints}

\subsubsection{6계층 아키텍처}

% [Figure 2 - 6-Layer Stack Architecture]
\begin{figure}[htbp]
	\centering
	\begin{scriptsize}
		\begin{verbatim}
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ L5. Application & Policy                                          ┃
┃   Streamlit UI | FastAPI REST | Offline Fallback Policy           ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃ L4. Generation & Grounding                                        ┃
┃   Prompt Template | TemplateResponder (Ontology-based Fallback)   ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃ L3. Context Shaping  ★ Core Contribution                          ┃
┃   Crop Filter (+0.5/×0.15) | Semantic Dedup | Memory-aware Rerank ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃ L2. Retrieval Core (HybridDAT - 3-Channel Fusion)                 ┃
┃   Dense (FAISS) | Sparse (TF-IDF) | PathRAG-lite (BFS 2-hop)      ┃
┃                    ↓ Score Normalization & Fusion                 ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃ L1. On-device Knowledge Store                                     ┃
┃   dense.faiss (mmap) | sparse.pkl | Causal Graph | Ontology (6)   ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
┃ L0. Device & Runtime (8GB RAM / Q4_K_M)                           ┃
┃   llama.cpp (Qwen3-0.6B) | MiniLM (90MB) | FAISS mmap enabled     ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
	\end{verbatim}
	\end{scriptsize}
	\caption{제안 시스템의 6계층 스택 아키텍처. L3 Context Shaping이 핵심 기여로, 토큰 절감을 통해 엣지 환경에서의 효율성을 극대화함.}
	\label{fig:architecture}
\end{figure}

\textbf{계층별 핵심 역할}:

\input{tables/methodology/layers}

%----------------------------------------------------------------------
\subsection{데이터 수집 및 전처리 파이프라인}

\subsubsection{데이터 수집}

본 연구의 지식 베이스는 세 가지 유형의 농업 문서로 구성된다: (1) 재배 매뉴얼 (농촌진흥청, 도농업기술원 PDF), (2) 기술 가이드 (스마트팜 코리아, 농업기술실용화재단 웹/PDF), (3) 작업 기록 (현장 농가 메모, Q\&A 게시판).

\subsubsection{전처리 파이프라인}

% [Figure 3 - Data Preprocessing Pipeline]
\begin{figure}[htbp]
	\centering
	\begin{scriptsize}
		\begin{verbatim}
┌─────────────────────────────────────────────────────────────────┐
│                  DATA PREPROCESSING PIPELINE                    │
├─────────────────────────────────────────────────────────────────┤
│  INPUT                                                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐                       │
│  │   PDF    │  │  Image   │  │   Text   │                       │
│  │ 농촌진흥청│  │ 현장사진 │  │ Q&A 게시판│                       │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘                       │
│       └─────────────┴─────────────┘                             │
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ OCR Processing (EasyOCR)                                    ││
│  │   • Image → Text conversion                                 ││
│  │   • Normalization: "25도" → 25℃, "EC 2.5" → EC 2.5 dS/m    ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ Semantic Chunking (200-500 tokens, 50 overlap)              ││
│  │   • Section-based split → Semantic merge → Overlap          ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ Metadata Extraction                                         ││
│  │   crop | category | causal_role | numeric_info | source     ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  OUTPUT: Chunks + Metadata → Knowledge Store                    │
└─────────────────────────────────────────────────────────────────┘
	\end{verbatim}
	\end{scriptsize}
	\caption{데이터 전처리 파이프라인. PDF/이미지/텍스트 입력에서 OCR 처리, 시맨틱 청킹, 메타데이터 추출을 거쳐 Knowledge Store로 인덱싱.}
	\label{fig:preprocessing}
\end{figure}

\subsubsection{OCR 및 텍스트 정규화}

이미지 기반 문서는 EasyOCR을 사용하여 텍스트로 변환한다. 정규화 규칙을 적용하여 온도(25도 $\rightarrow$ 25℃), EC(전기전도도 2.5 $\rightarrow$ EC 2.5 dS/m), pH(산도 6.5 $\rightarrow$ pH 6.5) 등 수치 표현을 통일한다.

\subsubsection{시맨틱 청킹 전략}

단순 길이 기반 분할 대신, 문서의 의미 구조를 보존하는 청킹을 적용한다. 섹션 기반 1차 분할 후 짧은 섹션은 연관 섹션과 병합하며, 50 토큰 오버랩으로 문맥 연속성을 확보한다. 청킹 파라미터: \texttt{CHUNK\_MIN\_TOKENS}=200, \texttt{CHUNK\_MAX\_TOKENS}=500, \texttt{CHUNK\_OVERLAP}=50.

\subsubsection{메타데이터 자동 추출}

각 청크에 대해 crop(작물), category(카테고리), causal\_role(인과관계 역할), numeric\_info(수치 정보), source(출처) 메타데이터를 규칙 기반으로 자동 추출한다.

%----------------------------------------------------------------------
\subsection{스마트팜 온톨로지}

\subsubsection{설계 배경}

온톨로지 설계는 Stanford 온톨로지 구축 방법론~\cite{ref13}과 기존 농업 온톨로지 연구~\cite{ref9,ref10,ref11}를 참조하여 스마트팜 도메인에 적합한 6개 개념 유형을 정의하였다. CropDP-KG~\cite{ref12}의 엔티티 구조와 AgriKG~\cite{ref21}의 농업 엔티티 분류를 참고하여 한국 스마트팜 환경에 맞게 구성하였다.

\subsubsection{개념 유형 정의}

\input{tables/methodology/ontology}

각 개념은 동의어/유의어 목록(alias)을 포함한다. 예를 들어 ``와사비''의 alias에는 ``산와사비'', ``본와사비''가 포함되어 사용자가 어떤 표현을 쓰더라도 동일 개념으로 인식한다.

%----------------------------------------------------------------------
\subsection{3채널 하이브리드 검색 (HybridDAT)}

\subsubsection{설계 근거}

Dense retrieval은 의미적 유사성 검색에 강하지만 ``EC 2.5 dS/m'' 같은 수치 정보 매칭에 취약하다. Sparse retrieval은 정확한 키워드 매칭에 강하지만 의미적 유사성을 놓칠 수 있다~\cite{ref5}. 본 시스템은 Dense-Sparse-PathRAG 3채널 융합과 질의 특성에 따른 동적 가중치 조정(Dynamic Alpha Tuning)을 적용한다.

\subsubsection{HybridDATRetriever 플로우}

% [Figure 4 - HybridDAT Retrieval Flow]
\begin{figure}[htbp]
	\centering
	\begin{scriptsize}
		\begin{verbatim}
┌─────────────────────────────────────────────────────────────────┐
│                    HybridDATRetriever Flow                      │
├─────────────────────────────────────────────────────────────────┤
│  Query: "와사비 적정 온도는?"                                    │
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 1. Ontology Matching                                        ││
│  │    OntologyMatcher.match() → {crop: 와사비, env: 온도}       ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 2. Dynamic Alpha Calculation                                ││
│  │    수치/단위 포함? → α_s +0.2 (Sparse 강화)                  ││
│  │    병해/재배?     → α_p ~0.3 (PathRAG 활성화)                ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 3. 3-Channel Parallel Search                                ││
│  │  ┌────────────┐ ┌────────────┐ ┌────────────┐               ││
│  │  │   Dense    │ │   Sparse   │ │  PathRAG   │               ││
│  │  │   FAISS    │ │   TF-IDF   │ │  BFS 2-hop │               ││
│  │  │    α_d     │ │    α_s     │ │    α_p     │               ││
│  │  └─────┬──────┘ └─────┬──────┘ └─────┬──────┘               ││
│  │        └──────────────┴──────────────┘                      ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 4. Score Fusion                                             ││
│  │    final = α_d×dense + α_s×sparse + α_p×path                ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  Output: Top-k × 2 Candidates → Context Shaping                 │
└─────────────────────────────────────────────────────────────────┘
	\end{verbatim}
	\end{scriptsize}
	\caption{HybridDATRetriever 검색 플로우. 온톨로지 매칭 후 Dynamic Alpha 계산, 3채널 병렬 검색, Score Fusion을 거쳐 후보 문서 생성.}
	\label{fig:hybriddat}
\end{figure}

\subsubsection{동적 가중치 규칙 (Dynamic Alpha)}

질의 내용을 분석하여 가중치를 자동 결정한다:

\input{tables/methodology/dynamic-alpha}

%----------------------------------------------------------------------
\subsection{인과관계 그래프 (PathRAG-lite)}

\subsubsection{설계 배경}

농업 도메인에서 ``고수온 $\rightarrow$ 연부병 발생 $\rightarrow$ 수온 관리'' 같은 인과 체인이 핵심 정보 구조를 형성한다~\cite{ref17}. GraphRAG~\cite{ref7}는 LLM으로 개체와 관계를 추출하므로 구축 비용이 높다(문서 1000개당 GPT-4 \$100+). 본 시스템은 규칙 기반 패턴 매칭으로 인과관계 그래프를 구축하여 비용을 \$0으로 절감한다.

\subsubsection{인과관계 역할 분류}

텍스트 패턴 매칭으로 문서의 역할을 분류한다:

\input{tables/methodology/causal-patterns}

\subsubsection{PathRAG-lite BFS 탐색}

PathRAG~\cite{ref8}의 경로 탐색 개념을 차용한 경량 구현이다. BFS(너비 우선 탐색) 기반 2-hop 탐색으로 원인$\rightarrow$결과$\rightarrow$해결책 문서를 수집한다.

\subsubsection{그래프 스키마}

CropDP-KG~\cite{ref12}와 AgriKG~\cite{ref21}의 스키마 설계를 참조하여 구성하였다.

\textbf{노드 타입}: practice(문서), crop, env, disease, nutrient, stage

\textbf{엣지 타입}:
\begin{itemize}
	\item \texttt{recommended\_for}: 작물 $\rightarrow$ 실천 (AgriKG~\cite{ref21})
	\item \texttt{associated\_with}: 병해 $\rightarrow$ 실천 (CropDP-KG~\cite{ref12})
	\item \texttt{mentions}: 실천 $\rightarrow$ 개념 (농업 온톨로지~\cite{ref10})
	\item \texttt{causes}: 실천 $\rightarrow$ 실천 (인과 추출~\cite{ref14,ref15})
	\item \texttt{solved\_by}: 실천 $\rightarrow$ 실천 (인과 추출~\cite{ref14,ref15})
\end{itemize}

%----------------------------------------------------------------------
\subsection{Context Shaping (컨텍스트 압축)}

엣지 LLM은 토큰이 곧 지연/전력 비용이므로, 검색 결과를 그대로 전달하지 않고 압축/필터링하는 것이 핵심이다.

\subsubsection{Context Shaping 파이프라인}

% [Figure 5 - Context Shaping Pipeline]
\begin{figure}[htbp]
	\centering
	\begin{scriptsize}
		\begin{verbatim}
┌─────────────────────────────────────────────────────────────────┐
│                  Context Shaping Pipeline                       │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────┐  │
│  │  INPUT  │ → │ CROP FILTER │ → │SEMANTIC DEDUP│ → │ OUTPUT  │  │
│  │ 16 docs │   │  ~12 docs   │   │   ~8 docs   │   │ 4 docs  │  │
│  └─────────┘   └─────────────┘   └─────────────┘   └─────────┘  │
├─────────────────────────────────────────────────────────────────┤
│  Crop Filter:                                                   │
│    • 작물 일치: score + 0.5 (관련 문서 우선)                     │
│    • 작물 불일치: score × 0.15 (무관한 작물 정보 억제)           │
│    • 작물 정보 없음: 유지                                        │
├─────────────────────────────────────────────────────────────────┤
│  Semantic Deduplication:                                        │
│    • cosine similarity ≥ 0.85 → 후순위 문서 제거                │
│    • 검색 결과의 다양성 확보 (MMR, VRSD 참조)                    │
├─────────────────────────────────────────────────────────────────┤
│  Memory-aware Reranking:                                        │
│    • RAM < 0.8GB  → none (skip, +0MB)                           │
│    • 0.8GB-1.5GB → LLM-lite (~0MB, llama.cpp 재사용)            │
│    • ≥ 1.5GB     → BGE Reranker (~500MB)                        │
└─────────────────────────────────────────────────────────────────┘
	\end{verbatim}
	\end{scriptsize}
	\caption{Context Shaping 파이프라인. Crop Filter, Semantic Dedup, Memory-aware Reranking을 통해 16개 검색 결과를 4개로 압축하여 토큰 절감.}
	\label{fig:context_shaping}
\end{figure}

\subsubsection{작물 필터링 (Crop-aware Filtering)}

농업 지식 그래프 연구~\cite{ref4,ref12}에서 작물별 맥락 의존성이 강조되었다. 질의의 작물과 문서의 작물 메타데이터를 비교하여 스코어를 조정한다.

\input{tables/methodology/crop-filter}

\subsubsection{시맨틱 중복 제거 (Semantic Deduplication)}

MMR~\cite{ref18}과 VRSD~\cite{ref19}를 참조하여 검색 결과의 다양성을 확보한다. 두 문서의 임베딩 벡터 간 코사인 유사도가 임계값($\theta$=0.85) 이상인 문서 쌍에서 후순위 문서를 제거한다.

\subsubsection{메모리 적응형 리랭킹}

런타임 가용 메모리에 따라 리랭커를 동적으로 선택한다:

\input{tables/methodology/reranking}

%----------------------------------------------------------------------
\subsection{엣지 배포 최적화}

\subsubsection{메모리 계층 구조 (RAM vs Flash)}

엣지 환경에서 ``벡터 인덱스가 RAM에 다 못 올라간다''는 병목을 해결하기 위해 계층적 메모리 구조를 설계하였다.

\begin{itemize}
	\item \textbf{RAM (Hot Data)}: Query Cache (LRU 128), Embedding Cache (LRU 256), FAISS mmap Active Pages, LLM Weights ($\sim$2.5GB)
	\item \textbf{Flash/SSD (Cold Data)}: dense.faiss (mmap), sparse.pkl, responses.jsonl, Causal Graph (in-memory built)
\end{itemize}

\subsubsection{LLM 양자화 전략}

llama.cpp의 GGUF 포맷~\cite{ref23}을 활용하여 Q4\_K\_M 양자화를 기본으로 적용한다.

\input{tables/methodology/quantization}

Q4\_K\_M은 중요한 레이어는 5비트, 나머지는 4비트로 혼합 양자화하여 품질 대비 메모리 효율의 최적점으로 평가된다.

\subsubsection{오프라인 폴백 모드}

네트워크 단절 또는 LLM 장애 시 다음과 같은 폴백 전략을 적용한다:

\begin{enumerate}
	\item \textbf{Similar Cache}: ResponseCache.get\_similar() - 임베딩 유사도 $\geq$ 0.9인 이전 유사 질의 응답 재활용
	\item \textbf{Template Response}: TemplateResponder.generate() - 온톨로지 매칭 기반 정형화된 응답 생성
	\item \textbf{Search Only}: LLM 없이 검색 결과만 반환
\end{enumerate}

%----------------------------------------------------------------------
\subsection{런타임 검증 및 신뢰도 표시}

\textit{Note: 본 섹션은 시스템에 내장된 런타임 검증 기능을 다룬다. Ablation Study, Benchmark 비교 등 연구 방법론으로서의 평가는 Section~\ref{sec:experiments}에서 상세히 기술한다.}

엣지 환경에서 LLM의 환각(hallucination) 위험을 완화하기 위해, 시스템은 응답 생성 시점에 다음과 같은 런타임 검증 메커니즘을 수행한다.

\subsubsection{근거 추적 (Source Attribution)}

생성된 응답의 각 주장에 대해 근거 문서를 명시적으로 연결한다. LLM 프롬프트에 검색된 문서와 함께 ``근거를 명시하라''는 지시를 포함하고, 응답 생성 후 주장-문서 간 임베딩 유사도를 계산하여 유사도가 임계값(0.7) 미만인 주장에 대해 경고를 표시한다.

\subsubsection{런타임 환각 감지}

% [Figure 6 - Verification Pipeline]
\begin{figure}[htbp]
	\centering
	\begin{scriptsize}
		\begin{verbatim}
┌─────────────────────────────────────────────────────────────────┐
│              Runtime Hallucination Detection Pipeline           │
├─────────────────────────────────────────────────────────────────┤
│  INPUT: LLM 생성 응답 + 검색된 근거 문서                         │
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 1. Claim Extraction                                         ││
│  │    응답에서 사실적 주장 추출 (수치, 권장사항 등)              ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 2. Evidence Matching                                        ││
│  │    주장-문서 임베딩 유사도 계산 (threshold: 0.7)             ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 3. Consistency Check                                        ││
│  │    수치 정보 일치 확인 (범위, 단위 검증)                     ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 4. Confidence Scoring                                       ││
│  │    HIGH (≥80%) | MEDIUM (≥60%) | LOW (<60%)                 ││
│  └─────────────────────────────────────────────────────────────┘│
│                     ↓                                           │
│  OUTPUT: 응답 + 신뢰도 표시 + 근거 문서 링크 + warnings          │
└─────────────────────────────────────────────────────────────────┘
	\end{verbatim}
	\end{scriptsize}
	\caption{런타임 환각 감지 파이프라인. Claim Extraction, Evidence Matching, Consistency Check를 통해 신뢰도(HIGH/MEDIUM/LOW)를 산출.}
	\label{fig:verification}
\end{figure}

\subsubsection{수치 정보 검증}

농업 도메인에서 수치 정보의 정확성은 특히 중요하다. 범위 검증(수온 10-25℃, pH 5.5-7.5 등 도메인 지식 기반 허용 범위), 일관성 검증(근거 문서 내 수치와 비교), 단위 검증(단위 변환 정확성 확인)을 적용한다.

\subsubsection{신뢰도 표시}

최종 응답에는 신뢰도 수준이 함께 제공된다:
\begin{itemize}
	\item \textbf{HIGH}: 모든 주장에 유사도 $\geq$0.8 근거 존재 - 응답 신뢰 가능
	\item \textbf{MEDIUM}: 일부 주장만 근거 확인 ($\geq$60\%) - 추가 확인 권장
	\item \textbf{LOW}: 근거 확인 불가 ($<$60\%) - 전문가 상담 권장
\end{itemize}

%----------------------------------------------------------------------
\subsection{관련 연구와의 차별점}

\textit{Note: 관련 연구에 대한 포괄적인 리뷰는 Section~\ref{sec:related_work}를 참조한다. 본 섹션에서는 제안 방법론의 핵심 차별점을 요약한다.}

\input{tables/methodology/comparison}
