# Strict minimal env contract (single .env)
LLM_BACKEND=openai_compatible
OPENAI_COMPAT_BASE_URL=https://api.featherless.ai/v1
OPENAI_COMPAT_API_KEY=
OPENAI_COMPAT_MODEL=openai/gpt-oss-120b

# Core runtime lane (smartfarm-search): local LLM + local embeddings
CORE_LLM_BACKEND=llama_cpp
CORE_LLMLITE_HOST=http://llama:8080
CORE_LLMLITE_MODEL=Qwen3-4B-Q4_K_M
CORE_EMBED_BACKEND=sentence_transformers_local
CORE_EMBED_MODEL=/app/models/embeddings/BAAI__bge-m3
CORE_EMBED_DIM=1024
CORE_EMBED_DEVICE=cpu
CORE_EMBED_BATCH_SIZE=8
CORE_EMBED_LOCAL_NORMALIZE=true

# Benchmark answer lane (Qwen3-4B on local llama.cpp, OpenAI-compatible endpoint)
ANSWER_OPENAI_COMPAT_BASE_URL=http://llama:8080/v1
ANSWER_OPENAI_COMPAT_API_KEY=local-dummy
ANSWER_OPENAI_COMPAT_MODEL=Qwen/Qwen3-4B

JUDGE_RUNTIME=api
# Judge lane defaults to Vertex OpenAI-compatible endpoint (RAGAS_* has priority).
RAGAS_BASE_URL=https://us-central1-aiplatform.googleapis.com/v1/projects/<PROJECT_ID>/locations/us-central1/endpoints/openapi
RAGAS_API_KEY=__VERTEX_ADC__
HF_TOKEN=

# DAT runtime controls
DAT_MODE=hybrid
FUSION_PROFILE_PATH=data/artifacts/fusion_weights.runtime.json
FUSION_PROFILE_META_PATH=data/artifacts/fusion_profile_meta.runtime.json
DAT_MIN_WEIGHT_PER_CHANNEL=0.10
DAT_MAX_WEIGHT_PER_CHANNEL=0.80
DAT_MAX_DELTA_PER_UPDATE=0.15
DAT_MIN_PROFILE_QUERIES=300
DAT_PROFILE_TTL_HOURS=168
