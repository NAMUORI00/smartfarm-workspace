version: "3.9"

services:
  qdrant:
    image: qdrant/qdrant:v1.15.4
    ports:
      - "6333:6333"
    volumes:
      - ./data/index/qdrant:/qdrant/storage

  falkordb:
    image: falkordb/falkordb:v4.6.1
    ports:
      - "6379:6379"
    volumes:
      - ./data/index/falkordb:/data
    environment:
      FALKORDB_ARGS: "--maxmemory 512mb"

  llama:
    image: ghcr.io/ggml-org/llama.cpp:server-cuda
    command:
      - --model
      - ${LLAMA_MODEL_PATH:-/models/Qwen3-4B-Q4_K_M.gguf}
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --ctx-size
      - ${LLAMA_CTX_SIZE:-8192}
      - --parallel
      - ${LLAMA_PARALLEL:-2}
      - --cont-batching
      - --n-gpu-layers
      - ${GPU_LAYERS:--1}
    ports:
      - "${LLAMA_HOST_PORT:-45857}:8080"
    volumes:
      - ./smartfarm-llm-inference/models:/models

  api:
    build: ./smartfarm-search
    depends_on:
      - qdrant
      - falkordb
      - llama
    ports:
      - "41177:41177"
    environment:
      LLM_BACKEND: ${LLM_BACKEND:-llama_cpp}
      OPENAI_COMPAT_BASE_URL: ${OPENAI_COMPAT_BASE_URL:-}
      OPENAI_COMPAT_API_KEY: ${OPENAI_COMPAT_API_KEY:-}
      OPENAI_COMPAT_MODEL: ${OPENAI_COMPAT_MODEL:-Qwen/Qwen3-4B}
      HF_TOKEN: ${HF_TOKEN:-}
      DAT_MODE: ${DAT_MODE:-hybrid}
      FUSION_PROFILE_PATH: ${FUSION_PROFILE_PATH:-data/artifacts/fusion_weights.runtime.json}
      FUSION_PROFILE_META_PATH: ${FUSION_PROFILE_META_PATH:-data/artifacts/fusion_profile_meta.runtime.json}
      DAT_MIN_WEIGHT_PER_CHANNEL: ${DAT_MIN_WEIGHT_PER_CHANNEL:-0.10}
      DAT_MAX_WEIGHT_PER_CHANNEL: ${DAT_MAX_WEIGHT_PER_CHANNEL:-0.80}
      DAT_MAX_DELTA_PER_UPDATE: ${DAT_MAX_DELTA_PER_UPDATE:-0.15}
      DAT_MIN_PROFILE_QUERIES: ${DAT_MIN_PROFILE_QUERIES:-300}
      DAT_PROFILE_TTL_HOURS: ${DAT_PROFILE_TTL_HOURS:-168}
      PRIVATE_STORE_DB_PATH: ${PRIVATE_STORE_DB_PATH:-data/kb/private_overlay.sqlite}
      LOG_PATH: ${LOG_PATH:-data/logs/query.log}
    volumes:
      - ./data:/app/data
