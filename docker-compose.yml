services:
  # ==============================================================================
  # LLM Inference (llama.cpp)
  # Base compose uses CPU image for portability.
  # For GPU, run with:
  #   docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
  # ==============================================================================
  llama:
    image: ghcr.io/ggml-org/llama.cpp:server
    container_name: smartfarm-llama
    command:
      - --model
      - ${LLAMA_MODEL_PATH:-/models/Qwen3-4B-Q4_K_M.gguf}
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --ctx-size
      - ${LLAMA_CTX_SIZE:-8192}
      - --parallel
      - ${LLAMA_PARALLEL:-1}
      - --cont-batching
    ports:
      - "${LLAMA_HOST_PORT:-45857}:8080"
    volumes:
      # Default: use models prepared by `smartfarm-search/setup.py`
      - ${LLAMA_MODELS_DIR:-./smartfarm-search/models}:/models
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 30
    restart: unless-stopped
    networks: ["private_net"]

  # ==============================================================================
  # RAG API (smartfarm-search)
  # ==============================================================================
  api:
    build:
      context: ./smartfarm-search
      dockerfile: Dockerfile
    image: smartfarm-rag-api:latest
    container_name: smartfarm-rag-api
    ports:
      - "41177:41177"
    environment:
      - PORT=41177
      - LLMLITE_HOST=${LLMLITE_HOST:-http://llama:8080}
      - LLMLITE_TIMEOUT=${LLMLITE_TIMEOUT:-300}
      - LLMLITE_MAX_TOKENS=${LLMLITE_MAX_TOKENS:-256}
      # Prevent accidental runtime downloads/calls from the private plane
      - HF_HUB_OFFLINE=1
      - TRANSFORMERS_OFFLINE=1

      # KB locations (SoT + inbox)
      - BASE_KB_PATH=${BASE_KB_PATH:-data/kb/base.sqlite}
      - OVERLAY_KB_PATH=${OVERLAY_KB_PATH:-data/kb/overlay.sqlite}
      - KB_INBOX_DIR=${KB_INBOX_DIR:-data/inbox/base_updates}

      # Retrieval defaults (edge-friendly)
      - EMBED_MODEL_ID=${EMBED_MODEL_ID:-minilm}
      - SPARSE_METHOD=${SPARSE_METHOD:-bm25}
      - ENABLE_CACHE=${ENABLE_CACHE:-true}
      - RERANKER_DEFAULT=${RERANKER_DEFAULT:-none}

      # Tri-Graph RAG (LinearRAG-inspired; clean-room implementation, LLM-free indexing)
      - TRIGRAPH_ENABLED=${TRIGRAPH_ENABLED:-true}
      - TRIGRAPH_INDEX_DIR=${TRIGRAPH_INDEX_DIR:-data/index/trigraph_edge}
      - TRIGRAPH_ENTITY_TOP_K=${TRIGRAPH_ENTITY_TOP_K:-10}
      - TRIGRAPH_ENTITY_THRESHOLD=${TRIGRAPH_ENTITY_THRESHOLD:-0.35}
      - TRIGRAPH_MAX_ITERATIONS=${TRIGRAPH_MAX_ITERATIONS:-3}
      - TRIGRAPH_TOP_K_SENTENCE=${TRIGRAPH_TOP_K_SENTENCE:-3}
      - TRIGRAPH_USE_PPR=${TRIGRAPH_USE_PPR:-true}
      - TRIGRAPH_PPR_DAMPING=${TRIGRAPH_PPR_DAMPING:-0.85}
      - TRIGRAPH_PPR_ITERS=${TRIGRAPH_PPR_ITERS:-16}

      # Fusion (Dense + Sparse + Tri-Graph)
      - FUSION_RRF_K=${FUSION_RRF_K:-60}
      - FUSION_DYNAMIC_WEIGHTS=${FUSION_DYNAMIC_WEIGHTS:-true}
      - FUSION_BASE_DENSE=${FUSION_BASE_DENSE:-0.45}
      - FUSION_BASE_SPARSE=${FUSION_BASE_SPARSE:-0.35}
      - FUSION_BASE_TRIGRAPH=${FUSION_BASE_TRIGRAPH:-0.20}

      # Optional: run without LLM generation (still does retrieval + template fallback)
      - OFFLINE_MODE=${OFFLINE_MODE:-false}
    volumes:
      - ./smartfarm-search/data:/app/data
      - ./smartfarm-search/.cache:/root/.cache
      # Data diode: ingress writes to inbox, private plane reads only
      - ./smartfarm-search/data/inbox:/app/data/inbox:ro
    depends_on:
      llama:
        condition: service_healthy
    restart: unless-stopped
    networks: ["private_net"]

  # ==============================================================================
  # Ingest Worker (async uploads -> overlay indices)
  # ==============================================================================
  ingest-worker:
    build:
      context: ./smartfarm-search
      dockerfile: Dockerfile
    image: smartfarm-rag-api:latest
    container_name: smartfarm-ingest-worker
    command: ["python", "-m", "core.Services.Ingest.ingest_worker"]
    environment:
      - LLMLITE_HOST=${LLMLITE_HOST:-http://llama:8080}
      - LLMLITE_TIMEOUT=${LLMLITE_TIMEOUT:-300}
      - LLMLITE_MAX_TOKENS=${LLMLITE_MAX_TOKENS:-256}
      # Prevent accidental runtime downloads/calls from the private plane
      - HF_HUB_OFFLINE=1
      - TRANSFORMERS_OFFLINE=1

      # Keep consistent with API container so overlays are compatible
      - EMBED_MODEL_ID=${EMBED_MODEL_ID:-minilm}
      - SPARSE_METHOD=${SPARSE_METHOD:-bm25}
      - TRIGRAPH_ENABLED=${TRIGRAPH_ENABLED:-true}
      - OVERLAY_ROOT_DIR=${OVERLAY_ROOT_DIR:-data/index/overlay_uploads}
      - UPLOADS_DIR=${UPLOADS_DIR:-data/uploads}
      - INGEST_DB_PATH=${INGEST_DB_PATH:-data/kb/overlay.sqlite}
      - SENSOR_DB_PATH=${SENSOR_DB_PATH:-data/kb/overlay_sensors.sqlite}

      # KB locations (SoT + inbox)
      - BASE_KB_PATH=${BASE_KB_PATH:-data/kb/base.sqlite}
      - OVERLAY_KB_PATH=${OVERLAY_KB_PATH:-data/kb/overlay.sqlite}
      - KB_INBOX_DIR=${KB_INBOX_DIR:-data/inbox/base_updates}
    volumes:
      - ./smartfarm-search/data:/app/data
      - ./smartfarm-search/.cache:/root/.cache
      # Data diode: ingress writes to inbox, private plane reads only
      - ./smartfarm-search/data/inbox:/app/data/inbox:ro
    depends_on:
      llama:
        condition: service_healthy
    healthcheck:
      disable: true
    restart: unless-stopped
    networks: ["private_net"]

  # ==============================================================================
  # Public Ingress Plane: external base bundle downloader (one-way into inbox)
  #
  # This service MUST NOT mount private KB/overlay volumes. It writes only into
  # ./smartfarm-search/data/inbox/ so the private plane can apply updates.
  #
  # Usage example:
  #   BASE_BUNDLE_URL="https://example.com/base.sqlite" \
  #   docker compose --profile ingress run --rm base-sync
  # ==============================================================================
  base-sync:
    image: curlimages/curl:8.5.0
    profiles: ["ingress"]
    container_name: smartfarm-base-sync
    environment:
      - BASE_BUNDLE_URL=${BASE_BUNDLE_URL:-}
      - BASE_MANIFEST_URL=${BASE_MANIFEST_URL:-}
    volumes:
      - ./smartfarm-search/data/inbox:/app/data/inbox
    entrypoint: ["sh", "-lc"]
    command:
      - |
        set -eu
        if [ -z "$${BASE_BUNDLE_URL:-}" ]; then
          echo "[base-sync][ERROR] BASE_BUNDLE_URL is required"
          exit 2
        fi
        TS="$$(date -u +%Y%m%dT%H%M%SZ)"
        OUT="/app/data/inbox/base_updates/$$TS"
        mkdir -p "$$OUT"
        echo "[base-sync] download: $$BASE_BUNDLE_URL -> $$OUT/base.sqlite"
        curl -fsSL "$$BASE_BUNDLE_URL" -o "$$OUT/base.sqlite"
        if [ -n "$${BASE_MANIFEST_URL:-}" ]; then
          echo "[base-sync] download: $$BASE_MANIFEST_URL -> $$OUT/manifest.json"
          curl -fsSL "$$BASE_MANIFEST_URL" -o "$$OUT/manifest.json"
        fi
        echo "$$TS" > /app/data/inbox/base_updates/LATEST
        echo "[base-sync] done: $$OUT"
    restart: "no"
    networks: ["ingress_net"]

  # ==============================================================================
  # Frontend UI
  # ==============================================================================
  frontend:
    build:
      context: ./smartfarm-frontend
      dockerfile: Dockerfile
    image: smartfarm-frontend:latest
    container_name: smartfarm-frontend
    ports:
      - "8501:8501"
    environment:
      - ERA_RAG_HOST=http://api:41177
      - ERA_RAG_TIMEOUT=${ERA_RAG_TIMEOUT:-300}
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    networks: ["private_net"]

networks:
  # Private Reasoning Plane: internal-only network (no internet egress)
  private_net:
    internal: true
  # Public Ingress Plane: internet-enabled network for base-sync only
  ingress_net: {}
